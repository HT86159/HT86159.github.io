<!-- # ðŸ“ Publications -->
## Selected Publications
<!-- Your representative paper (with image) -->
<div class='paper-box'>
  <div class='paper-box-image'>
    <div>
      <div class="badge">ICLR 2026</div>
      <img src='images/euq-lvlm.png' alt="EUQ Framework Illustration" width="100%">
    </div>
  </div>
  <div class='paper-box-text' markdown="1">

[Detecting Misbehaviors of Large Vision-Language Models by Evidential Uncertainty Quantification](https://openreview.net/forum?id=xJT4fXJr1Q) \
**Tao Huang**, Rui Wang, Xiaofei Liu, Yi Qin, Li Duan, Liping Jing

[**Code**](https://github.com/HT86159/EUQ) | [**PDF**](https://openreview.net/forum?id=xJT4fXJr1Q)

- **Efficient Framework**: A training-free method that quantifies uncertainty using pre-logits features in a single forward pass.
- **Novel Insight**: Layer-wise dynamic analysis reveals hallucinations correspond to high internal conflict, while OOD failures correspond to high ignorance.
- **Superior Performance**: Outperforms strong baselines on four state-of-the-art LVLMs, improving AUROC by **10.4%** and AUPR by **5.3%** on average.

  </div>
</div>
