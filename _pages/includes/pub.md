<!-- # üìù Publications -->
## ‚≠ê Selected Publications

<div class='paper-box'>
  <div class='paper-box-image'>
    <div>
      <div class="badge">ICLR 2026</div>
      <img src='../../images/euq-lvlm.png' alt="EUQ Framework" width="100%">
    </div>
  </div>
  <div class='paper-box-text' markdown="1">

<span style="font-size: 1.5em;"> [**Detecting Misbehaviors of Large Vision-Language Models by Evidential Uncertainty Quantification**](https://openreview.net/forum?id=xJT4fXJr1Q) </span>

<span style="font-size: 0.9em;"> **Tao Huang**, Rui Wang, Xiaofei Liu, Yi Qin, Li Duan, Liping Jing; | [üì¶**Code**](https://github.com/HT86159/EUQ) | [ü§ó**Huggingface**](https://huggingface.co/datasets/TerryHWong/Misbehavior-Bench)  </span>

<div style="border-top: 1px solid #eaecef; margin: 15px 0;"></div>

**Efficient Framework**: A training-free method that quantifies uncertainty using pre-logits features in a single forward pass.

**Novel Insight**: Layer-wise dynamic analysis reveals hallucinations correspond to high internal conflict, while OOD failures correspond to high ignorance.

**Superior Performance**: Outperforms strong baselines on four state-of-the-art LVLMs, improving AUROC by **10.4%** and AUPR by **5.3%** on average.

  </div>
</div>
